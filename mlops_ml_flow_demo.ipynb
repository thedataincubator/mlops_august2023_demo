{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ee8705",
   "metadata": {},
   "source": [
    "# Machine Learning Operations (MLOps) & MLflow demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944034c",
   "metadata": {},
   "source": [
    "## What is MLOps?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8d0ac",
   "metadata": {},
   "source": [
    "MLOps takes a software engineering approach to machine learning — from training the machine learning models to deploying them into production. MLOps is a collection of best practices to increase the value from machine learning through systematic improvement of the process.\n",
    "\n",
    "The term MLOps is the combination of two fields ML (Machine Learning) and Ops (Operations) – which may refer to development/system operations. MLOps is a systematic process for developing, training, deploying, and optimizing all kinds of machine learning models (e.g., statistical, deep learning, and natural language processing) that enable AI-based applications. \n",
    "\n",
    "Organizations are increasingly relying on machine learning (ML) models to drive business value, but the operationalization of these models remains a challenge. Unlike traditional software applications, ML models require special considerations due to their reliance on data, the complexity of the algorithms used, and the need for continual model improvement. Without proper MLOps practices, organizations risk deploying models that are inaccurate, unreliable, or do not scale, leading to negative business outcomes and wasted resources.\n",
    "\n",
    "The motivation for doing MLOps is to address these challenges and ensure that organizations can deliver high-quality, reliable ML models to production environments. MLOps helps to streamline the ML lifecycle by providing a framework for data management, model training, deployment, and monitoring. It also provides a way to manage the complex infrastructure required to support ML workloads, including specific data storage and compute requirements.\n",
    "\n",
    "ML models require special considerations compared to traditional software development because they are reliant on data, which can be noisy, incomplete, or biased. This means that data management and preprocessing are critical components of MLOps. In addition, ML models require ongoing improvement and iteration, which requires specialized tooling and processes to support experimentation and model tracking.\n",
    "\n",
    "Most MLOps platforms offer collaborative model construction, training, assessment, and deployment in addition to data preparation to drive the modeling and training processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1521ed",
   "metadata": {},
   "source": [
    "## MLOps steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e7f6d",
   "metadata": {},
   "source": [
    "1. **Collect data**: Gather the large quantity of high quality data is often the longest and most expensive step.\n",
    "<br><br>\n",
    "1. **Process data**: Most data needs to extensively cleaned before it is ready for ML. Supervised ML is the most powerful type of ML and requires each piece of data have a trustworthy label.\n",
    "<br><br>\n",
    "1. **Train and improve models**: Select ML algorithms, then train the model, try different hyperparameters. This steps takes the most amount of compute resources. At a large scale, ML tracking software is useful.\n",
    "<br><br>\n",
    "1. **Deploy models to production**: Package trained model and dependencies for a specific production environment.\n",
    "<br><br>\n",
    "1. **Monitor models in production**: Once the model is being served to end users, it has to be watched. There are standard software in production requirements. The additional ML requirements are changes in data. The distribution of data could change, there could be new features, and new target labels.\n",
    "<br><br>\n",
    "1. **Repeat steps 1 - 5**: ML is iterative process. Each step is an ongoing process that needs change management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793c1ba",
   "metadata": {},
   "source": [
    "## MLflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22d1daad",
   "metadata": {},
   "source": [
    "MLflow is an open source platform that is designed to help manage the ML lifecycle.  \n",
    "\n",
    "Primary MLflow components:\n",
    "\n",
    "* Tracking: Keeps track of all the runs - code versions, start/end times, metrics, and other information.\n",
    "* Projects: Provides a standard way to package all of the relevant code.\n",
    "* Models: Ensures formatting and keeps metadata to enables to be served in production environments\n",
    "* Model Registry: A centralized model store to help collaboratively manage the full lifecycle of an MLflow model.   \n",
    "\n",
    "![workflow overview](images/quickstart_tracking_overview.png)\n",
    "[Image source](https://mlflow.org/)\n",
    "\n",
    "Let's walk through how to use MLflow to track machine learning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf9b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing()\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418897e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81cccd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models and their possible hyperparameter options\n",
    "from sklearn.ensemble     import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "models = {\n",
    "    \"RidgeRegression\": {\n",
    "        \"model\": Ridge(),\n",
    "        \"params\": {\n",
    "            \"alpha\": [0, 1]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestRegression\": {\n",
    "        \"model\": RandomForestRegressor(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [5, 10],\n",
    "            \"max_depth\": [3, 5]\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a9afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/.local/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Run ID: c2bbcf1045004161a05a5bcf94ef554c\n",
      "Parameter: std_fit_time      -> [3.13553033e-03 5.12214757e-06]\n",
      "Parameter: mean_test_score   -> [-0.59714628 -0.5974207 ]\n",
      "Parameter: split0_test_score -> [0.58939904 0.58945712]\n",
      "Parameter: std_test_score    -> [1.69328141 1.69370267]\n",
      "Parameter: mean_fit_time     -> [0.0030121  0.00068514]\n",
      "Parameter: split2_test_score -> [-2.99177553 -2.99264591]\n",
      "Parameter: split1_test_score -> [0.61093764 0.61092669]\n",
      "Parameter: param_alpha       -> [0 1]\n",
      "Parameter: params            -> [{'alpha': 0}, {'alpha': 1}]\n",
      "Parameter: mean_score_time   -> [0.00020138 0.00014901]\n",
      "Parameter: Model             -> RidgeRegression\n",
      "Parameter: std_score_time    -> [5.16374256e-05 7.78671819e-07]\n",
      "Parameter: rank_test_score   -> [1 2]\n",
      "Metric:    CV std score      -> 1.6932814109447893\n",
      "Metric:    Test score        -> 0.5140713616727152\n",
      "Metric:    CV mean score     -> -0.5971462847453054\n",
      "------------------------------\n",
      "Results for Run ID: e49b45cf9c53456aba1ac32376a51144\n",
      "Parameter: std_fit_time      -> [0.00065526 0.0018228  0.0003066  0.00159533]\n",
      "Parameter: mean_test_score   -> [0.5515311  0.56079706 0.65283243 0.65612097]\n",
      "Parameter: split0_test_score -> [0.54428478 0.55104963 0.64045471 0.64585854]\n",
      "Parameter: std_test_score    -> [0.0135184  0.01126306 0.0096314  0.01031273]\n",
      "Parameter: param_n_estimators -> [5 10 5 10]\n",
      "Parameter: mean_fit_time     -> [0.05194529 0.11044812 0.07943757 0.15900636]\n",
      "Parameter: split2_test_score -> [0.53983307 0.55476089 0.65409789 0.65227774]\n",
      "Parameter: split1_test_score -> [0.57047545 0.57658066 0.66394469 0.67022663]\n",
      "Parameter: params            -> [{'max_depth': 3, 'n_estimators': 5}, {'max_depth': 3, 'n_estimators': 10}, {'max_depth': 5, 'n_estimators': 5}, {'max_depth': 5, 'n_estimators': 10}]\n",
      "Parameter: mean_score_time   -> [0.00091259 0.00148479 0.0011669  0.00202624]\n",
      "Parameter: Model             -> RandomForestRegression\n",
      "Parameter: std_score_time    -> [1.32571212e-04 9.87045879e-05 1.35155275e-05 3.14401303e-05]\n",
      "Parameter: rank_test_score   -> [4 3 2 1]\n",
      "Parameter: param_max_depth   -> [3 3 5 5]\n",
      "Metric:    CV std score      -> 0.012217739867294164\n",
      "Metric:    Test score        -> 0.45495322741749095\n",
      "Metric:    CV mean score     -> 0.6564820219059846\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run cross validation experiments and track results with MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from   mlflow.tracking         import MlflowClient\n",
    "from   sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from   sklearn.metrics         import mean_squared_error\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    with mlflow.start_run() as run:\n",
    "        # Run grid search cross validation\n",
    "        clf = GridSearchCV(model_info[\"model\"], model_info[\"params\"], cv=3)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Log parameters, metrics, and model\n",
    "        mlflow.log_param(\"Model\", model_name)\n",
    "        for param_name, param_value in clf.cv_results_.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "\n",
    "        # Cross validation scores\n",
    "        cv_scores = cross_val_score(clf.best_estimator_, X_train, y_train, cv=3)\n",
    "        mlflow.log_metric(\"CV mean score\", np.mean(cv_scores))\n",
    "        mlflow.log_metric(\"CV std score\", np.std(cv_scores))\n",
    "\n",
    "        # Test score\n",
    "        test_pred = clf.best_estimator_.predict(X_test)\n",
    "        test_score = mean_squared_error(y_test, test_pred)\n",
    "        mlflow.log_metric(\"Test score\", test_score)\n",
    "\n",
    "        mlflow.sklearn.log_model(clf.best_estimator_, f\"{model_name}_model\")\n",
    "\n",
    "        # Get the current run's details using MLflow client\n",
    "        run_id = run.info.run_id\n",
    "        run_data = client.get_run(run_id).data\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Results for Run ID: {run_id}\")\n",
    "        for param_key, param_value in run_data.params.items():\n",
    "            print(f\"Parameter: {param_key:<17} -> {param_value}\")\n",
    "\n",
    "        for metric_key, metric_value in run_data.metrics.items():\n",
    "            print(f\"Metric:    {metric_key:<17} -> {metric_value}\")\n",
    "        print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1665d",
   "metadata": {},
   "source": [
    "## Looking at experimental  results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe02fbb",
   "metadata": {},
   "source": [
    "The results with MLflow’s tracking UI. To start the UI, run the following at the command line:\n",
    "\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "Then navigate to http://localhost:5000 in a browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de5a3d4",
   "metadata": {},
   "source": [
    "## MLflow limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5276c",
   "metadata": {},
   "source": [
    "1. Relatively new library, thus there are bugs and rough edges.\n",
    "2. May have too many features for smaller ML projects.\n",
    "3. No support for collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd858b5",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005bee9d",
   "metadata": {},
   "source": [
    "* MLOps is set of best practices to systematically improve machine learning, especially in production environments.\n",
    "* MLflow is a Python package that supports more mature MLOps workflows.\n",
    "* MLflow can be used to track machine learning experiments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
